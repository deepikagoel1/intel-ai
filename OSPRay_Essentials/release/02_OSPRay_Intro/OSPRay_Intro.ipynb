{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intel&reg; OSPRay Introduction\n",
    "--------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "* Get familiar with the Intel® OSPRay renderer and API.\n",
    "* Edit and compile code for the first lesson: the minimal ospTutorial sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. What is Intel&reg; OSPRay?\n",
    "Intel® OSPRay is a ray-tracing framework for high-quality visualization rendering. Intel OSPRay goals are to go beyond previous proof-of-concept ray tracing systems for visualization and offer a complete turn-key solution for existing production visualization software packages than can run efficiently on current hardware while offering modular device support for future hardware architectures. In particular, it introduces:\n",
    "\n",
    "Small device-independent API for general but visualization-oriented ray tracing\n",
    "Specific, CPU-oriented implementation of this API that provides an efficient visualization rendering engine for general-purpose CPU workstations and HPC resources\n",
    "\n",
    "### 2. OSPRay Goals\n",
    "\n",
    "The main challenge with ray tracing as a visualization rendering backend is that it does not easily map to existing rasterization oriented APIs—it requires new APIs that more generally target visualization applications, and then integration work for those applications to utilize the new APIs. More specifically, OSPRay is:\n",
    "\n",
    "* **A library, not a visualization tool**. Rather than designing a brand new visualization package, OSPRay is a _library_ that many different visualization tools can then leverage.\n",
    "* **A rendering solution for visualization tools**. Visualization tools are complex, often relying on middleware libraries (such as VTK). OSPRay does not replace or compete with such middleware, and focuses exclusively on the visualization pipeline’s rendering component. By broadening supported rendering primitives, shading models, data set sizes, etc OSPRay gives existing visualization tools’ analysis stages additional choices in what they can ask the rendering stage to do.\n",
    "* **Focused on visualization rendering**. OSPRay emphasizes the rendering features needed by production scientific visualization - simple color-mapped geometry and palettes, and different renderers (primary, ambient occlusion and path tracing) that cater to a variety of needs. It does not aim for the photorealism of professional graphics, nor for game performance.\n",
    "* **Focused on HPC visualization rendering**. Since “simple” problems are successfully handled by existing GPU-based approaches, we explicitly focus on problems that remain challenging for visualization applications, such as large data, volume rendering and advanced shading. In particular, we strive to enable effective and performant visualization across all kinds of HPC resources, even those that lack GPUs. We do not discourage GPU use for all problems, but offer an efficient alternative for platforms that do not have any, and, more generally, wish to advance ray tracing solutions for those problems that can benefit from its characteristics.\n",
    "* **Focused on performance**. Though we do not have to achieve game-like frame rates, interactive data exploration requires performant rendering. Our implementation makes efficient use of threading, vectorization, and, if desired, node-parallelism; and leverages the most efficient ray tracing technologies available.\n",
    "\n",
    "### 3. Intel OSPRay API\n",
    "The Intel OSPRay API is a layer between visualization applications and low-level hardware resources. The figure below shows the Intel OSPRay API (the \"layer cake\") in relation to other hardware and software components commonly found in visualization applications. The API is designed to be platform independent - this implementation targets CPUs, but the API should also map to GPUs, integrated graphics, and so on. It is a low level of abstraction similar to that of OpenGL*, which is the abstraction level that modern visualization tools use for rendering. Similar to solutions in OpenGL and GPGPU, Intel OSPRay API focuses on a low-level data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/Figure3.png\" style=\"width:50%\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. API Categories\n",
    "The OSPRay API exposes the following categories of objects:\n",
    "\n",
    "* **OSPFrameBuffers** hold the final result of a rendered frame. Information held can contain, but is not limited to, pixel colors, depth values, and accumulation information.\n",
    "* **OSPData** are 1D data arrays, similar to “buffers” in a GPGPU context. In addition to the typical scalar and 2-, 3-, or 4-dimensional vector data, data arrays can also contain references to other actors (including to other data arrays), in device-abstract fashion.\n",
    "* **OSPGeometry** contain geometric surface primitives such as triangles, spheres, cylinders, etc.\n",
    "* **OSPVolumes** represent 3D scalar fields that can produce, for any 3D position, a scalar value that a volume renderer can sample.\n",
    "* **OSPTransferFunctions** map scalars to RGBA colors.\n",
    "* **OSPModels** are collections of geometries and volumes – the parent objects of the hierarchy. Time-varying data are vectors of OSP- Models.\n",
    "* **OSPCameras** generate primary rays for renderers to compute on.\n",
    "* **OSPRenderers** use cameras, models, etc, to render pixels. OSPRay defines two renderers: \n",
    "    * `scivis` renderer that combines many rendering techniques into a single renderer. In this renderer we focus on the needs of scientific visualization: we implement an OpenGL-like material model, with customizable contributions of transparency, shadows, ambient occlusion, and fully integrated volume rendering.\n",
    "    * `pathtracer` renderer, a fully photo-realistic renderer that can be used for generating high-quality publication images, and that has since seen adoption even outside of scientific visualization.\n",
    "* **OSPLights, OSPTextures, and OSPMaterials** specify additional inputs for rendering, lighting, shading, etc.\n",
    "\n",
    "#### Commit transactions\n",
    "An important aspect OSPRay is that parameters/data that affect any of the objects do not get passed to objects individually; instead, parameters are not visible at all to objects until they get explicitly committed to an object via a call to **ospCommit(object)**, at which time all previously additions or changes to parameters are visible at the same time. If a user wants to change the state of an existing object (e.g., to change the origin of an already existing camera) it is perfectly valid to do so, as long as the changed parameters are recommitted.\n",
    "\n",
    "The commit semantics allow for batching up multiple small changes, and specifies exactly when changes to objects will occur. This is important to ensure performance and consistency for devices crossing a PCI* bus, or across a network. every commit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 5. First Lesson: ospTutorial\n",
    "\n",
    "In order to get a sense for all of the various API components that need to come together to write an OSPRay visualizer we present ospTutorial - a minimal demonstration that exercises those components.\n",
    "\n",
    "`ospTutorial` will create an image of two triangles, rendered with the pathtracer renderer. The image `firstFrame.png` shows the result after one call to `ospRenderFrame` – jagged edges and noise in the shadow can be seen. These are not incorrect renderings but are the result of the random nature of the ray tracing used to generate the image. In future lessons we will learn how to issue multiple calls to `ospRenderFrame` and converge the resulting image to display anti-aliased edges, for example.\n",
    "\n",
    "#### 5.1 The Program Flow\n",
    "The following is a general flow for the ospTutorial program. Though these steps are described for this program they generalize such that other OSPRay roughly implement these steps. Comments in the program follow along with these steps.\n",
    "\n",
    "* Step 1 - Set up common objects to be used in the program\n",
    "* Step 2 - Execute ospInit() to initialize the renderer\n",
    "* Step 3 - Setup the camera into the scene\n",
    "* Step 4 - Setup the scene\n",
    "    * Step 4.1 Feeding the model/vertex data to OSPRay\n",
    "    * Step 4.2 - Create a material \n",
    "    * Step 4.3 - Put the mesh into a model and apply material\n",
    "    * Step 4.4 - Put the model into a group (collection of models)\n",
    "    * Step 4.5 - Put the group into an instance (give the group a world transform)\n",
    "    * Step 4.6 - Put the instance in the world\n",
    "    * Step 4.7 - Create and setup light for Ambient Occlusion\n",
    "* Step 5 - Setup of the renderer\n",
    "    * Step 5.1 - Create renderer\n",
    "    * Step 5.2 - Create and setup framebuffer\n",
    "    * Step 5.3 - Render one frame\n",
    "    * Step 5.4 - Access framebuffer and write its content as PNG file\n",
    "* Step 6 - Shutdown system and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/ospTutorial.cpp\n",
    "\n",
    "\n",
    "// system includes\n",
    "#include <alloca.h>\n",
    "#include <errno.h>\n",
    "#include <stdint.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "// ospray and math includes\n",
    "#include \"ospray/ospray_util.h\"\n",
    "#include \"rkcommon/math/rkmath.h\"\n",
    "#include \"rkcommon/math/vec.h\"\n",
    "\n",
    "// includes to STB for writing out a PNG image\n",
    "#define STB_IMAGE_WRITE_IMPLEMENTATION\n",
    "#include \"stb/stb_image_write.h\"\n",
    "\n",
    "using namespace rkcommon::math;\n",
    "\n",
    "// ################################################################################\n",
    "// A simple function that uses the STB library to write out the framebuffer in\n",
    "// PNG format.\n",
    "\n",
    "void writePNG(const char *fileName, const vec2i &size, const uint32_t *pixel) {\n",
    "  constexpr int nChannels{4};\n",
    "  const int stride{nChannels * size.x};\n",
    "  stbi_write_png(fileName, size.x, size.y, nChannels, pixel, stride);\n",
    "}\n",
    "\n",
    "// ################################################################################\n",
    "// The entry point into the program that exercises the API\n",
    "\n",
    "int main(int argc, const char **argv) {\n",
    "\n",
    "  // ########## Step 1 - set up common objects to be used in the program\n",
    "\n",
    "  // Define the width and height of the framebuffer\n",
    "  // image size\n",
    "  vec2i imgSize;\n",
    "  imgSize.x = 1024;  // width\n",
    "  imgSize.y = 768;   // height\n",
    "\n",
    "  // camera\n",
    "  // Placing the camera at the origin <0,0,0>\n",
    "  float cam_pos[] = {0.f, 0.f, 0.f};\n",
    "\n",
    "  // Orient the camera noting Y-up\n",
    "  float cam_up[] = {0.f, 1.f, 0.f};\n",
    "\n",
    "  // set the camera view direction\n",
    "  float cam_view[] = {0.1f, 0.f, 1.f};\n",
    "\n",
    "  // triangle mesh data\n",
    "  // 4 vertices each with a XYZ position\n",
    "  float vertex[] = {\n",
    "    -1.0f, -1.0f, 3.0f, \n",
    "    -1.0f, 1.0f, 3.0f,\n",
    "    1.0f, -1.0f, 3.0f, \n",
    "    0.1f,  0.1f, 0.3f};\n",
    "\n",
    "  // 4 colors denoted by RGBA\n",
    "  float color[] = {\n",
    "    0.9f, 0.5f, 0.5f, 1.0f, \n",
    "    0.8f, 0.8f, 0.8f, 1.0f,\n",
    "    0.8f, 0.8f, 0.8f, 1.0f, \n",
    "    0.5f, 0.9f, 0.5f, 1.0f};\n",
    "\n",
    "  // index for the triangles\n",
    "  int32_t index[] = {0, 1, 2, 1, 2, 3};\n",
    "\n",
    "  // ########## Step 2 - execute ospInit() to initialize the renderer\n",
    "    printf(\"initialize OSPRay...\");\n",
    "\n",
    "  // initialize OSPRay; OSPRay parses (and removes) its commandline parameters,\n",
    "  OSPError init_error = ospInit(&argc, argv);\n",
    "  if (init_error != OSP_NO_ERROR)\n",
    "    return init_error;\n",
    "\n",
    "  printf(\"done!\\n\");\n",
    "  \n",
    "  // ########## Step 3 - setup the camera into the scene\n",
    "  printf(\"setting up camera...\");\n",
    "\n",
    "  // Feeding the camera data to OSPRay\n",
    "  // create and setup camera\n",
    "  OSPCamera camera = ospNewCamera(\"perspective\");\n",
    "  ospSetFloat(camera, \"aspect\", imgSize.x / (float)imgSize.y);\n",
    "  ospSetParam(camera, \"position\", OSP_VEC3F, cam_pos);\n",
    "  ospSetParam(camera, \"direction\", OSP_VEC3F, cam_view);\n",
    "  ospSetParam(camera, \"up\", OSP_VEC3F, cam_up);\n",
    "  ospCommit(camera);  // commit each object to indicate modifications are done\n",
    "\n",
    "  printf(\"done!\\n\");\n",
    "\n",
    "  // ########## Step 4 - setup the scene\n",
    "  printf(\"setting up scene...\");\n",
    "\n",
    "  // #################### Step 4.1 Feeding the model/vertex data to OSPRay\n",
    "  // create and setup model and mesh\n",
    "  OSPGeometry mesh = ospNewGeometry(\"mesh\");\n",
    "\n",
    "  OSPData data = ospNewSharedData1D(vertex, OSP_VEC3F, 4);\n",
    "  // alternatively with an OSPRay managed OSPData\n",
    "  // OSPData managed = ospNewData1D(OSP_VEC3F, 4);\n",
    "  // ospCopyData1D(data, managed, 0);\n",
    "\n",
    "  ospCommit(data);\n",
    "  ospSetObject(mesh, \"vertex.position\", data);\n",
    "  ospRelease(data);  // we are done using this handle\n",
    "\n",
    "  data = ospNewSharedData1D(color, OSP_VEC4F, 4);\n",
    "  ospCommit(data);\n",
    "  ospSetObject(mesh, \"vertex.color\", data);\n",
    "  ospRelease(data);\n",
    "\n",
    "  data = ospNewSharedData1D(index, OSP_VEC3UI, 2);\n",
    "  ospCommit(data);\n",
    "  ospSetObject(mesh, \"index\", data);\n",
    "  ospRelease(data);\n",
    "\n",
    "  ospCommit(mesh);\n",
    "\n",
    "  // #################### Step 4.2 - create a material \n",
    "  OSPMaterial mat = ospNewMaterial(\"pathtracer\", \"obj\");\n",
    "  ospCommit(mat);\n",
    "\n",
    "\n",
    "  // #################### Step 4.3 - put the mesh into a model and apply material\n",
    "  OSPGeometricModel model = ospNewGeometricModel(mesh);\n",
    "  ospSetObject(model, \"material\", mat);\n",
    "  ospCommit(model);\n",
    "  ospRelease(mesh);\n",
    "  ospRelease(mat);\n",
    "\n",
    "  // #################### Step 4.4 - put the model into a group (collection of models)\n",
    "  OSPGroup group = ospNewGroup();\n",
    "  ospSetObjectAsData(group, \"geometry\", OSP_GEOMETRIC_MODEL, model);\n",
    "  ospCommit(group);\n",
    "  ospRelease(model);\n",
    "\n",
    "  /// #################### Step 4.5 - put the group into an instance (give the group a world transform)\n",
    "  OSPInstance instance = ospNewInstance(group);\n",
    "  ospCommit(instance);\n",
    "  ospRelease(group);\n",
    "\n",
    "  // #################### Step 4.6 - put the instance in the world\n",
    "  OSPWorld world = ospNewWorld();\n",
    "  ospSetObjectAsData(world, \"instance\", OSP_INSTANCE, instance);\n",
    "  ospRelease(instance);\n",
    "\n",
    "  // #################### Step 4.7 - create and setup light for Ambient Occlusion\n",
    "  OSPLight light = ospNewLight(\"ambient\");\n",
    "  ospCommit(light);\n",
    "  ospSetObjectAsData(world, \"light\", OSP_LIGHT, light);\n",
    "  ospRelease(light);\n",
    "\n",
    "  ospCommit(world);\n",
    "\n",
    "  printf(\"done!\\n\");\n",
    "\n",
    "  // print out world bounds\n",
    "  OSPBounds worldBounds = ospGetBounds(world);\n",
    "  printf(\"\\nworld bounds: ({%f, %f, %f}, {%f, %f, %f}\\n\\n\",\n",
    "         worldBounds.lower[0], worldBounds.lower[1], worldBounds.lower[2],\n",
    "         worldBounds.upper[0], worldBounds.upper[1], worldBounds.upper[2]);\n",
    "\n",
    "\n",
    "  // ########## Step 5 - setup of the renderer\n",
    "  printf(\"setting up renderer...\");\n",
    "\n",
    "  // #################### Step 5.1 - create renderer\n",
    "  OSPRenderer renderer =\n",
    "      ospNewRenderer(\"pathtracer\");  // choose path tracing renderer\n",
    "\n",
    "  // complete setup of renderer\n",
    "  ospSetFloat(renderer, \"backgroundColor\", 1.0f);  // white, transparent\n",
    "  ospCommit(renderer);\n",
    "\n",
    "  // #################### Step 5.2 - create and setup framebuffer\n",
    "  OSPFrameBuffer framebuffer =\n",
    "      ospNewFrameBuffer(imgSize.x, imgSize.y, OSP_FB_SRGBA,\n",
    "                        OSP_FB_COLOR | /*OSP_FB_DEPTH |*/ OSP_FB_ACCUM);\n",
    "  ospResetAccumulation(framebuffer);\n",
    "\n",
    "  printf(\"rendering initial frame to firstFrame.png...\");\n",
    "\n",
    "  // #################### Step 5.3 - render one frame\n",
    "  ospRenderFrameBlocking(framebuffer, renderer, camera, world);\n",
    "\n",
    "  // #################### Step 5.4 - access framebuffer and write its content as PNG file\n",
    "  const uint32_t *fb = (uint32_t *)ospMapFrameBuffer(framebuffer, OSP_FB_COLOR);\n",
    "  writePNG(\"firstFrame.png\", imgSize, fb);\n",
    "  ospUnmapFrameBuffer(fb, framebuffer);\n",
    "\n",
    "  printf(\"done!\\n\");\n",
    "\n",
    "  ospUnmapFrameBuffer(fb, framebuffer);\n",
    "\n",
    "  printf(\"done!\\n\");\n",
    "\n",
    "  // ########## Step 6 - shutdown system and clean up\n",
    "  printf(\"\\ncleaning up objects...\");\n",
    "\n",
    "  // final cleanups\n",
    "  ospRelease(renderer);\n",
    "  ospRelease(camera);\n",
    "  ospRelease(framebuffer);\n",
    "  ospRelease(world);\n",
    "\n",
    "  printf(\"done!\\n\");\n",
    "\n",
    "  ospShutdown();\n",
    "\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Build the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q build.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Run the Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./q run.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Resulting Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(11, 8.5), dpi=72, facecolor='w', edgecolor='k')\n",
    "\n",
    "img = mpimg.imread('firstFrame.png')\n",
    "plt.axis('off')\n",
    "imgplot = plt.imshow(img,aspect=None,interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Summary\n",
    "\n",
    "You have arrived at the end of this lesson. During this lesson, you:\n",
    "\n",
    "* Learned about Intel OSPRay, a framework for ray-traced visualization rendering that advances ray tracing as a solution to some of today’s key rendering challenges in scientific visualization\n",
    "* Got familiar with Intel OSPRay API for multi-core and many-core CPU architectures that runs well on hardware ranging from laptops to large-scale HPC resources\n",
    "* Learned how to use the Intel OSPRay API to write a minimal viewer program for displaying mesh geometry\n",
    "\n",
    "***\n",
    "## Resources\n",
    "* M. Pharr and G. Humphreys. Physically Based Rendering: From Theory to Implementation. Morgan Kaufman, 3rd edition, 2016.\n",
    "* P. Shirley. Ray Tracing in One Weekend Series. Editors: Steve Hollasch, Trevor David Black. Version/Edition: v3.2.0. Date: 2020-07-18. URL (series): https://raytracing.github.io/\n",
    "* I. Wald et al., \"OSPRay - A CPU Ray Tracing Framework for Scientific Visualization,\" in IEEE Transactions on Visualization and Computer Graphics, vol. 23, no. 1, pp. 931-940, Jan. 2017, doi: 10.1109/TVCG.2016.2599041."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<html><body><span style=\"color:green\"><h1>Next: ospExamples - an Example of Intel® OSPRay Techniques and Procedural Scenes</h1></span></body></html>\n",
    "\n",
    "[Click Here](../03_ospExamples/ospExamples.ipynb)\n",
    "\n",
    "<html><body><span style=\"color:green\"><h1>Back: Overview</h1></span></body></html>\n",
    "\n",
    "[Click Here](../../Overview.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (Intel® oneAPI)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
